{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e2991b",
   "metadata": {},
   "source": [
    "### Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496eb24b",
   "metadata": {},
   "source": [
    "Обучить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2828893f",
   "metadata": {},
   "source": [
    "### Гипотеза"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18956692",
   "metadata": {},
   "source": [
    "Обучение на датасете, где применяли аугментацию из списка, одна функция на одно изображение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5971853e-060d-4d2d-b8fe-73446e03ac01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f212f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_experiment = 'augoff'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e5c83",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baadac34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room', 'bathroom', 'inner_corridor', 'public_place', 'floor_finish', 'floor_init', 'ceiling_finish', 'wall_finish', 'wall_init', 'door_room', 'toilet_yes', 'bath_yes', 'esocket_yes', 'kitchen_furniture_yes', 'radiator', 'floor_without', 'ceiling_without', 'wall_without', 'window_trim', 'window', 'floor_pipes', 'garbage', 'place_door', 'place_radiator', 'ventilation_shaft', 'sink_yes', 'conditioner', 'smoke_detector', 'ventilation_grille', 'fire_detectors', 'dynamics', 'switch_box_flat', 'switch_box_public', 'xbk', 'water_pipes_mop', 'water_pipes_flat', 'water_meter', 'heating_riser', 'smoke_exhaust_valve', 'electrical_cable', 'electrical_riser', 'lamp', 'door_mop', 'door_entrance', 'socket_box', 'tongue_groove _blocks', 'tile_plinth', 'pantry', 'bad_light']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "\n",
    "path_anns = '../data/datasets/original/annotations/default.json'\n",
    "\n",
    "with open(path_anns, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "list_labels = [d['name'] for d in data['categories']['label']['labels']]\n",
    "print(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db1eff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes = len(list_labels)\n",
    "device = 'cuda:0'\n",
    "\n",
    "lr = 5e-4\n",
    "epochs = 10\n",
    "batch_size = 688\n",
    "layers_to_unfreeze = 2\n",
    "\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c392bd",
   "metadata": {},
   "source": [
    "### Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5e0dc66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_small_384_in22ft1k',\n",
       " 'convnext_small_in22ft1k',\n",
       " 'convnext_small_in22k',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_384_in22ft1k',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_tiny_in22ft1k',\n",
       " 'convnext_tiny_in22k',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.list_models('convnext*', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7d3db",
   "metadata": {},
   "source": [
    "Инициализируем модель и посмотрим конфигурации модели при тренировки, чтобы добавить их в трансформации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54174f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_224.pth',\n",
       " 'num_classes': 21841,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'pool_size': (7, 7),\n",
       " 'crop_pct': 0.875,\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'stem.0',\n",
       " 'classifier': 'head.fc',\n",
       " 'architecture': 'convnext_large_in22k'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('convnext_large_in22k', pretrained=True, num_classes=n_classes)\n",
    "model.default_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7608a6",
   "metadata": {},
   "source": [
    "Посмотрим количество параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55b104fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество параметров модели: 196 МЛ\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Количество параметров модели: {round(total_params / 1000000)} МЛ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f26906",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db16f3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "\n",
    "\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "                                [\n",
    "                                    A.Resize(width=224, height=224),        \n",
    "                                    A.Normalize(\n",
    "                                        mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225],\n",
    "                                        max_pixel_value=255.0,\n",
    "                                    ),\n",
    "                                    \n",
    "                                    A.pytorch.ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "                                [\n",
    "                                    A.Resize(width=224, height=224),\n",
    "                                    A.Normalize(\n",
    "                                            mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225],\n",
    "                                            max_pixel_value=255.0,\n",
    "                                        ),\n",
    "\n",
    "                                    A.pytorch.ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = val_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01555ec2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4020b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path_csv: str, path_imgs: str, transforms=None):\n",
    "        \"\"\"\n",
    "        :param path_imgs: path to image folder.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = pd.read_csv(path_csv)\n",
    "        self.path_imgs = path_imgs\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        file_name = self.df.iloc[index, 0]\n",
    "        path_img = f'{self.path_imgs}/{file_name}.jpg'\n",
    "\n",
    "        img = cv2.imread(path_img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformered = self.transforms(image=img)\n",
    "            img = transformered['image']\n",
    "            \n",
    "        \n",
    "        targets = self.df.iloc[index, 1:]\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'image': img,\n",
    "            'targets': targets,\n",
    "            'path_img': path_img\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c1769",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d956167c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def get_f1(preds: torch.tensor, targets: torch.tensor):\n",
    "    \n",
    "    e = 1e-10\n",
    "        \n",
    "    TP = sum(targets[preds == 1] == 1)\n",
    "    FP = sum(targets[preds == 1] == 0)\n",
    "    FN = sum(targets[preds == 0] == 1)\n",
    "    \n",
    "    precision = TP / (TP + FP + e)\n",
    "    recall = TP / (TP + FN + e)\n",
    "    f1 = 2 * precision * recall / (precision + recall + e)\n",
    "    \n",
    "    return round(f1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29564784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_subf1(\n",
    "    preds: torch.tensor,\n",
    "    targets: torch.tensor\n",
    ") -> np.array:\n",
    "\n",
    "    batch_subf1 = []\n",
    "    for axis in range(targets.shape[-1]):\n",
    "        subtargets = targets[:, axis]\n",
    "        subpreds = preds[:, axis]\n",
    "        subf1 = get_f1(subpreds, subtargets)\n",
    "        batch_subf1.append(subf1)\n",
    "\n",
    "    return batch_subf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50bfd82",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ffcca2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device, threshold, n_classes):\n",
    "    \n",
    "    losses = []\n",
    "    f1s = []\n",
    "    all_preds = np.array([]).reshape(0, n_classes) \n",
    "    all_targets = np.array([]).reshape(0, n_classes)\n",
    "    \n",
    "    model.train()\n",
    "    for data in tqdm(dataloader, total=len(dataloader)):\n",
    "        \n",
    "        data, targets = data['image'].to(device), data['targets'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(data)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        preds = torch.where(outputs > threshold, 1, 0)\n",
    "                        \n",
    "        loss = criterion(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_preds = np.vstack((all_preds, preds.detach().cpu()))\n",
    "        all_targets = np.vstack((all_targets, targets.detach().cpu()))\n",
    "        \n",
    "    train_loss = np.mean(losses)\n",
    "    train_micro_f1 = get_f1(all_preds, all_targets)\n",
    "    train_micro_subf1 = get_subf1(all_preds, all_targets)\n",
    "    train_macro_f1 = sum(train_micro_subf1) / n_classes\n",
    "    \n",
    "    return train_loss, train_micro_f1, train_micro_subf1, train_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7532f29a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device, threshold, n_classes):\n",
    "    \n",
    "    losses = []\n",
    "    f1s = []\n",
    "    all_preds = np.array([]).reshape(0, n_classes) \n",
    "    all_targets = np.array([]).reshape(0, n_classes)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader, total=len(dataloader)):\n",
    "            data, targets = data['image'].to(device), data['targets'].to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "            preds = torch.where(outputs > threshold, 1, 0)\n",
    "\n",
    "            all_preds = np.vstack((all_preds, preds.detach().cpu()))\n",
    "            all_targets = np.vstack((all_targets, targets.detach().cpu()))\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "    val_loss = np.mean(losses)\n",
    "    val_micro_f1 = get_f1(all_preds, all_targets)\n",
    "    val_micro_subf1 = get_subf1(all_preds, all_targets)\n",
    "    val_macro_f1 = sum(val_micro_subf1) / n_classes\n",
    "        \n",
    "    return val_loss, val_micro_f1, val_micro_subf1, val_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6dbadfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, layers_to_unfreeze):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in list(model.parameters())[:-layers_to_unfreeze]:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66992e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_layers(model):\n",
    "\n",
    "    params_to_update = model.parameters()\n",
    "\n",
    "    print('Params to learn:')\n",
    "    params_to_update = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print('\\t', name)\n",
    "\n",
    "    return params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d8d1fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(epochs, model, optimizer, criterion, path):\n",
    "    torch.save({\n",
    "                'epoch': epochs,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48420ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def save_plot(name_metric: str, train: list, val: list, path_save_plot: str) -> None:\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(train, color='orange', label=f'train {name_metric}')\n",
    "    plt.plot(val, color='red', label=f'val {name_metric}')\n",
    "    plt.xticks(range(len(train)))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(name_metric)\n",
    "    plt.legend()\n",
    "    plt.savefig(path_save_plot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eb298-b7d4-48cf-a110-877bb4555ed1",
   "metadata": {},
   "source": [
    "Если появились изменения в составе лейблов, необходимо убедиться, что название лейблов и цветов и их количество соответствует нововведениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cade30f-8bce-4e01-a079-49278f770588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f8f36e-f937-4632-adc9-f3daf3133625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_num_labels = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3160d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_plot_subf1(val_micro_subf1s: list, name_metric: str, path_save_plot: str) -> None:\n",
    "\n",
    "    stacked = np.vstack(val_micro_subf1s)\n",
    "    num_epochs = stacked.shape[0]\n",
    "\n",
    "    list_labels = [\n",
    "        'room', 'bathroom', 'inner_corridor', 'public_place', 'floor_finish',\n",
    "        'floor_init', 'ceiling_finish', 'wall_finish', 'wall_init',\n",
    "        'door_room', 'toilet_yes', 'bath_yes', 'esocket_yes',\n",
    "        'kitchen_furniture_yes', 'radiator', 'floor_without',\n",
    "        'ceiling_without', 'wall_without', 'window_trim', 'window',\n",
    "        'floor_pipes', 'garbage', 'place_door', 'place_radiator',\n",
    "        'ventilation_shaft', 'sink_yes', 'conditioner', 'smoke_detector',\n",
    "        'ventilation_grille', 'fire_detectors', 'dynamics', 'switch_box_flat',\n",
    "        'switch_box_public', 'xbk', 'water_pipes_mop', 'water_pipes_flat',\n",
    "        'water_meter', 'heating_riser', 'smoke_exhaust_valve',\n",
    "        'electrical_cable', 'electrical_riser', 'lamp', 'door_mop',\n",
    "        'door_entrance', 'socket_box', 'tongue_groove _blocks', 'tile_plinth',\n",
    "        'pantry', 'bad_light'\n",
    "    ]\n",
    "\n",
    "    colors = list(mcolors.CSS4_COLORS.values())[:all_num_labels]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    for i, label in enumerate(list_labels):\n",
    "        plt.plot(stacked[:, i], color=colors[i], label=f'{label}')\n",
    "\n",
    "    plt.title('Val')\n",
    "    plt.xticks(range(num_epochs))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(name_metric)\n",
    "    plt.legend()\n",
    "    plt.savefig(path_save_plot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f0ff0",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b500b283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_imgs_train = '../data/datasets/augoff/images'\n",
    "path_imgs_val = '../data/datasets/original/images/default'\n",
    "\n",
    "path_csv_train = '../data/datasets/augoff/annotations/train.csv'\n",
    "path_csv_val = '../data/datasets/csv/val.csv'\n",
    "\n",
    "ds_train = ImageDataset(path_csv_train, path_imgs_train, train_transforms)\n",
    "ds_val = ImageDataset(path_csv_val, path_imgs_val, val_transforms)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4214c4f",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b0bdd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac050cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t head.fc.weight\n",
      "\t head.fc.bias\n"
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, layers_to_unfreeze)\n",
    "params_to_update = get_training_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03cb8e5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): Sequential(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=49, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87752bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params_to_update, lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecc7f9",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9de168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:32:06<00:00, 33.55s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:33<02:12, 33.16s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:18<00:00, 27.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.508 | loss: 0.15243845717724325\n",
      "Val macro f1: 0.644 | loss 0.11359090656042099\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:25:15<00:00, 32.85s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:32<02:11, 32.79s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:15<00:00, 27.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.705 | loss: 0.10271248560060155\n",
      "Val macro f1: 0.715 | loss 0.10170845687389374\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:24:52<00:00, 32.82s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:33<02:12, 33.09s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:19<00:00, 27.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.756 | loss: 0.09170363380601912\n",
      "Val macro f1: 0.737 | loss 0.09699552059173584\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:29:24<00:00, 33.27s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:32<02:10, 32.75s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:16<00:00, 27.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.786 | loss: 0.08532697593272735\n",
      "Val macro f1: 0.751 | loss 0.09471991658210754\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:27:02<00:00, 33.03s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:32<02:10, 32.51s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:16<00:00, 27.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.807 | loss: 0.08093869339938116\n",
      "Val macro f1: 0.759 | loss 0.09327141791582108\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:27:12<00:00, 33.05s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:32<02:11, 32.88s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:16<00:00, 27.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.825 | loss: 0.07769907765115552\n",
      "Val macro f1: 0.763 | loss 0.09251884371042252\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:27:47<00:00, 33.11s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:32<02:10, 32.52s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:15<00:00, 27.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.842 | loss: 0.07517935551376856\n",
      "Val macro f1: 0.766 | loss 0.09207281470298767\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [5:37:34<00:00, 34.10s/it]  \n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Corrupt JPEG data: 43 extraneous bytes before marker 0xd9\n",
      " 20%|██        | 1/5 [00:33<02:15, 33.78s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 5/5 [02:19<00:00, 27.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train macro f1: 0.852 | loss: 0.07315543478335997\n",
      "Val macro f1: 0.773 | loss 0.09207652509212494\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 402/594 [3:48:27<1:45:52, 33.09s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "dir_logs = f'../logs/{name_experiment}'\n",
    "\n",
    "if os.path.exists(dir_logs):\n",
    "    shutil.rmtree(dir_logs)\n",
    "\n",
    "if not os.path.exists(dir_logs):\n",
    "    os.makedirs(dir_logs)\n",
    "    \n",
    "best_macro_f1 = 0\n",
    "train_losses, val_losses = [], []\n",
    "train_micro_f1s, val_micro_f1s = [], []\n",
    "train_macro_f1s, val_macro_f1s = [], []\n",
    "val_micro_subf1s = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    \n",
    "    train_loss, train_micro_f1, train_micro_subf1, train_macro_f1 = train(\n",
    "                                                                            model,\n",
    "                                                                            dl_train,\n",
    "                                                                            optimizer,\n",
    "                                                                            criterion,\n",
    "                                                                            device,\n",
    "                                                                            threshold,\n",
    "                                                                            n_classes\n",
    "    )\n",
    "    \n",
    "    val_loss, val_micro_f1, val_micro_subf1, val_macro_f1 = validate(\n",
    "                                                                        model,\n",
    "                                                                        dl_val,\n",
    "                                                                        criterion,\n",
    "                                                                        device,\n",
    "                                                                        threshold,\n",
    "                                                                        n_classes\n",
    "    )\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    train_micro_f1s.append(train_micro_f1)\n",
    "    val_micro_f1s.append(val_micro_f1)\n",
    "    \n",
    "    train_macro_f1s.append(train_macro_f1)\n",
    "    val_macro_f1s.append(val_macro_f1)\n",
    "    \n",
    "    val_micro_subf1s.append(val_micro_subf1)\n",
    "    \n",
    "    print(f\"Train macro f1: {train_macro_f1:.3f} | loss: {train_loss}\")\n",
    "    \n",
    "    print(f'Val macro f1: {val_macro_f1:.3f} | loss {val_loss}')\n",
    "            \n",
    "    if best_macro_f1 < val_macro_f1:\n",
    "        \n",
    "        cur_best_weights = f'{dir_logs}/{name_experiment}_prec_{best_macro_f1:.3f}.pth'\n",
    "        \n",
    "        if os.path.exists(cur_best_weights):\n",
    "            os.remove(cur_best_weights)\n",
    "               \n",
    "        path_best_weights = f'{dir_logs}/{name_experiment}_prec_{val_macro_f1:.3f}.pth'\n",
    "        \n",
    "        save_model(epochs, model, optimizer, criterion, path_best_weights)\n",
    "        best_macro_f1 = val_macro_f1.copy()\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    name_metric='loss',\n",
    "    train=train_losses,\n",
    "    val= val_losses,\n",
    "    path_save_plot = f'../logs/{name_experiment}/losses.jpg'\n",
    ")\n",
    "\n",
    "save_plot(\n",
    "    name_metric='micro_f1',\n",
    "    train=train_micro_f1s,\n",
    "    val= val_micro_f1s,\n",
    "    path_save_plot = f'../logs/{name_experiment}/micro_f1.jpg'\n",
    ")\n",
    "\n",
    "save_plot(\n",
    "    name_metric='macro_f1',\n",
    "    train=train_macro_f1s,\n",
    "    val= val_macro_f1s,\n",
    "    path_save_plot = f'../logs/{name_experiment}/macro_f1.jpg'\n",
    ")\n",
    "\n",
    "save_plot_subf1(\n",
    "    val_micro_subf1s,\n",
    "    name_metric='micro f1',\n",
    "    path_save_plot=f'../logs/{name_experiment}/micro_subf1.jpg'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d12c50",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce94fb1c-a7d4-46d5-86db-2ff212d3158a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room', 'bathroom', 'inner_corridor', 'public_place', 'floor_finish', 'floor_init', 'ceiling_finish', 'wall_finish', 'wall_init', 'door_room', 'toilet_yes', 'bath_yes', 'esocket_yes', 'kitchen_furniture_yes', 'radiator', 'floor_without', 'ceiling_without', 'wall_without', 'window_trim', 'window', 'floor_pipes', 'garbage', 'place_door', 'place_radiator', 'ventilation_shaft', 'sink_yes', 'conditioner', 'smoke_detector', 'ventilation_grille', 'fire_detectors', 'dynamics', 'switch_box_flat', 'switch_box_public', 'xbk', 'water_pipes_mop', 'water_pipes_flat', 'water_meter', 'heating_riser', 'smoke_exhaust_valve', 'electrical_cable', 'electrical_riser', 'lamp', 'door_mop', 'door_entrance', 'socket_box', 'tongue_groove _blocks', 'tile_plinth', 'pantry', 'bad_light']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path_anns = '../data/datasets/original/annotations/default.json'\n",
    "\n",
    "with open(path_anns, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "list_labels = [d['name'] for d in data['categories']['label']['labels']]\n",
    "print(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b879ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/augoff/augoff_prec_0.779.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "n_classes = len(list_labels)\n",
    "name_experiment = 'augoff'\n",
    "device = 'cuda:0'\n",
    "batch_size = 256\n",
    "threshold = 0.5\n",
    "\n",
    "path_weights = f'../logs/{name_experiment}/'\n",
    "path_weights = list(Path(path_weights).rglob('*.pth'))[0]\n",
    "print(path_weights)\n",
    "\n",
    "path_imgs = '../data/datasets/original/images/default'\n",
    "path_csv_test = '../data/datasets/csv/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff1ecb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): Sequential(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=49, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model = timm.create_model('convnext_large_in22k', pretrained=False, num_classes=n_classes)\n",
    "checkpoint = torch.load(path_weights)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9c9d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_lines(preds: np.array, probs: np.array, targets: np.array) -> list:\n",
    "    lines = [('background', 'predictions')]\n",
    "\n",
    "    for pred, prob in zip(preds, probs):\n",
    "        lines.append(('prediction', f'{pred}: {prob:.2f}'))\n",
    "\n",
    "    lines += [('background', 'targets')]\n",
    "\n",
    "    for target in targets:\n",
    "        lines.append(('target', target))\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03c7d2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimal_font_scale(text: str, width: int, scaling_weight: float) -> float:\n",
    "    for scale in reversed(range(0, 60, 1)):\n",
    "        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/scaling_weight, thickness=1)\n",
    "        new_width = textSize[0][0]\n",
    "        if (new_width <= width):\n",
    "            return scale/scaling_weight/5\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511c5770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualization(path_img: str, path_save: str, lines: list) -> None:\n",
    "    \n",
    "    image = cv2.imread(path_img)\n",
    "    \n",
    "    file_name = Path(path_img).name\n",
    "    \n",
    "    if len(lines) <= 3:\n",
    "        line_shift = 0.2\n",
    "    else:\n",
    "        line_shift = 0.05\n",
    "\n",
    "    alpha = 0.8\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    overlay = image.copy()\n",
    "\n",
    "    x, y = 100, 100\n",
    "    h_rect = int(h*0.1*len(lines))\n",
    "    w_rect = int(w*0.22)\n",
    "\n",
    "    cv2.rectangle(overlay, (x, y), (x+w_rect, y+h_rect), (0, 0, 0), -1)\n",
    "\n",
    "    image_with_rect = cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0)\n",
    "\n",
    "    if w + h > 2000:\n",
    "        scaling_weight = 10\n",
    "    elif 1000 < w + h < 2000:\n",
    "        scaling_weight = 20\n",
    "    elif 500 < w + h < 2000:\n",
    "        scaling_weight = 35\n",
    "    else:\n",
    "        scaling_weight = 45\n",
    "        \n",
    "    predictions = [text.split(':')[0] for status, text in lines if status == 'prediction']\n",
    "    targets = [text.split(':')[0] for status, text in lines if status == 'target']\n",
    "    \n",
    "    for i, (status, text) in enumerate(lines, start=1):\n",
    "        if status == 'background':\n",
    "            color = (139, 0, 255)\n",
    "        elif status == 'prediction':\n",
    "            if text.split(':')[0] in targets:\n",
    "                color = (152, 251, 152)\n",
    "            else:\n",
    "                color = (255, 255, 255)\n",
    "        elif status == 'target':\n",
    "            if text in predictions:\n",
    "                color = (152, 251, 152)\n",
    "            else:\n",
    "                color = (255, 255, 255)\n",
    "            \n",
    "        cv2.putText(\n",
    "            image_with_rect,\n",
    "            text,\n",
    "            (int(x+(w_rect*0.1)), y+(i*int(h_rect*line_shift))),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=get_optimal_font_scale(text, w, scaling_weight),\n",
    "            color=color,\n",
    "            thickness=round((w * h) / (1000 * 1000))\n",
    "        )\n",
    "    \n",
    "    cv2.imwrite(f'{path_save}/{file_name}', image_with_rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d48ba",
   "metadata": {},
   "source": [
    "Визуализируем `k` случайных изображений в которых модель предсказала хотя бы один лейбл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae1a65d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  2.24it/s]                       "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "k = 3\n",
    "\n",
    "path_save = f'../reports/{name_experiment}/visualization'\n",
    "\n",
    "if os.path.exists(path_save):\n",
    "    shutil.rmtree(path_save)\n",
    "\n",
    "if not os.path.exists(path_save):\n",
    "    os.makedirs(path_save)\n",
    "\n",
    "counter = 0\n",
    "ds_test = ImageDataset(path_csv_test, path_imgs, test_transforms)\n",
    "dl_test = DataLoader(ds_test, batch_size=1, shuffle=True)\n",
    "\n",
    "columns = ds_test.df.columns[1:].to_numpy()\n",
    "\n",
    "pbar = tqdm(total=k)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    while counter <= k:\n",
    "        batch = next(iter(dl_test))\n",
    "        data, target = batch['image'].to(device), batch['targets'].to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        preds = torch.where(outputs > threshold, 1, 0)\n",
    "        \n",
    "        outputs = outputs.detach().cpu().numpy()[0]\n",
    "        probs = outputs[np.where(outputs > threshold)]\n",
    "\n",
    "        mask = preds.detach().cpu().numpy()[0].astype(bool)\n",
    "        preds = columns[mask]\n",
    "        \n",
    "        mask = target.detach().cpu().numpy()[0].astype(bool)\n",
    "        targets = columns[mask]\n",
    "        \n",
    "        if len(preds) != 0: \n",
    "            pbar.update(1)\n",
    "            path_img = batch['path_img'][0]\n",
    "            image = cv2.imread(path_img)\n",
    "            lines = get_lines(preds, probs, targets)\n",
    "            visualization(path_img=path_img, path_save=path_save, lines=lines)\n",
    "            \n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86c8943",
   "metadata": {},
   "source": [
    "### Test metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12125e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "def get_f1(preds: torch.tensor, targets: torch.tensor):\n",
    "    \n",
    "    e = 1e-10\n",
    "        \n",
    "    TP = sum(targets[preds == 1] == 1)\n",
    "    FP = sum(targets[preds == 1] == 0)\n",
    "    FN = sum(targets[preds == 0] == 1)\n",
    "    \n",
    "    precision = TP / (TP + FP + e)\n",
    "    recall = TP / (TP + FN + e)\n",
    "    f1 = 2 * precision * recall / (precision + recall + e)\n",
    "    \n",
    "    return round(f1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d13f3f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_subf1(\n",
    "    preds: torch.tensor,\n",
    "    targets: torch.tensor\n",
    ") -> np.array:\n",
    "\n",
    "    batch_subf1 = []\n",
    "    for axis in range(targets.shape[-1]):\n",
    "        subtargets = targets[:, axis]\n",
    "        subpreds = preds[:, axis]\n",
    "        subf1 = get_f1(subpreds, subtargets)\n",
    "        batch_subf1.append(subf1)\n",
    "\n",
    "    return batch_subf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd27e2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = ImageDataset(path_csv_test, path_imgs, test_transforms)\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a77e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[ACorrupt JPEG data: premature end of data segment\n",
      "\n",
      "  8%|▊         | 1/12 [00:11<02:09, 11.80s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:23<02:00, 12.02s/it]\u001b[ACorrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 3038 extraneous bytes before marker 0xd9\n",
      "\n",
      " 25%|██▌       | 3/12 [00:35<01:45, 11.71s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:47<01:33, 11.73s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:59<01:24, 12.05s/it]\u001b[ACorrupt JPEG data: premature end of data segment\n",
      "\n",
      " 50%|█████     | 6/12 [01:10<01:10, 11.70s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [01:21<00:57, 11.45s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [01:31<00:44, 11.04s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [01:43<00:33, 11.30s/it]\u001b[A\n",
      " 83%|████████▎ | 10/12 [01:54<00:22, 11.09s/it]\u001b[A\n",
      " 92%|█████████▏| 11/12 [02:06<00:11, 11.30s/it]\u001b[ACorrupt JPEG data: premature end of data segment\n",
      "\n",
      "100%|██████████| 12/12 [02:10<00:00, 10.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test micro f1: 0.830\n",
      "Total test macro f1: 0.792\n",
      "room: 0.84\n",
      "bathroom: 0.87\n",
      "inner_corridor: 0.74\n",
      "public_place: 0.82\n",
      "floor_finish: 0.86\n",
      "floor_init: 0.78\n",
      "ceiling_finish: 0.89\n",
      "wall_finish: 0.94\n",
      "wall_init: 0.71\n",
      "door_room: 0.89\n",
      "toilet_yes: 0.83\n",
      "bath_yes: 0.84\n",
      "esocket_yes: 0.81\n",
      "kitchen_furniture_yes: 0.75\n",
      "radiator: 0.84\n",
      "floor_without: 0.79\n",
      "ceiling_without: 0.85\n",
      "wall_without: 0.84\n",
      "window_trim: 0.88\n",
      "window: 0.92\n",
      "floor_pipes: 0.89\n",
      "garbage: 0.74\n",
      "place_door: 0.84\n",
      "place_radiator: 0.83\n",
      "ventilation_shaft: 0.56\n",
      "sink_yes: 0.94\n",
      "conditioner: 1.00\n",
      "smoke_detector: 0.79\n",
      "ventilation_grille: 0.83\n",
      "fire_detectors: 0.85\n",
      "dynamics: 0.58\n",
      "switch_box_flat: 0.84\n",
      "switch_box_public: 0.73\n",
      "xbk: 0.62\n",
      "water_pipes_mop: 0.62\n",
      "water_pipes_flat: 0.73\n",
      "water_meter: 0.97\n",
      "heating_riser: 0.76\n",
      "smoke_exhaust_valve: 0.67\n",
      "electrical_cable: 0.81\n",
      "electrical_riser: 0.50\n",
      "lamp: 0.89\n",
      "door_mop: 0.70\n",
      "door_entrance: 0.84\n",
      "socket_box: 0.63\n",
      "tongue_groove _blocks: 0.85\n",
      "tile_plinth: 0.80\n",
      "pantry: 0.53\n",
      "bad_light: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "all_preds = np.array([]).reshape(0, n_classes) \n",
    "all_targets = np.array([]).reshape(0, n_classes) \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dl_test):\n",
    "        data, targets = data['image'].to(device), data['targets'].to(device)\n",
    "            \n",
    "        outputs = model(data)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        preds = torch.where(outputs > threshold, 1, 0)\n",
    "                \n",
    "        all_preds = np.vstack((all_preds, preds.detach().cpu()))\n",
    "        all_targets = np.vstack((all_targets, targets.detach().cpu()))\n",
    "    \n",
    "cms = multilabel_confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "micro_f1 = get_f1(all_preds, all_targets)\n",
    "all_subf1 = get_subf1(all_preds, all_targets)\n",
    "macro_f1 = sum(all_subf1) / n_classes\n",
    "\n",
    "print(f'Total test micro f1: {micro_f1:.03f}')\n",
    "print(f'Total test macro f1: {macro_f1:.03f}')\n",
    "\n",
    "for label, f1 in zip(list_labels, all_subf1):\n",
    "    print(f'{label}: {f1:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ac219-e456-45b7-aefb-cccedbf756aa",
   "metadata": {},
   "source": [
    "### Предыдущая модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea940e1-9835-47fb-a2e6-5dd3c576b181",
   "metadata": {},
   "source": [
    "Метрика на текущем тестовом датасете прошлой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9915e2-3673-442b-9d35-33cbff413cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_weights = '../weights/decor_mvp140623.pth'\n",
    "path_imgs = '../data/datasets/original/images/default'\n",
    "path_csv_test = '../data/datasets/csv/test.csv'\n",
    "\n",
    "device = 'cuda:0'\n",
    "batch_size = 256\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb435a56-3b73-458e-af73-5b3bc9bdbc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_test = ImageDataset(path_csv_test, path_imgs, test_transforms)\n",
    "dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ac3db4-32b1-42b4-b597-f4331e0a0717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "old_list_labels = [\n",
    "    'room', 'bathroom', 'inner_corridor', 'public_place', 'floor_finish',\n",
    "    'floor_init', 'ceiling_finish', 'wall_finish', 'wall_init', 'door_room',\n",
    "    'toilet_yes', 'bath_yes', 'esocket_yes', 'kitchen_furniture_yes',\n",
    "    'radiator', 'floor_without', 'ceiling_without', 'wall_without',\n",
    "    'window_trim', 'window', 'floor_pipes', 'garbage', 'place_door',\n",
    "    'place_radiator', 'ventilation_shaft', 'sink_yes', 'conditioner',\n",
    "    'smoke_detector', 'ventilation_grille', 'fire_detectors', 'dynamics',\n",
    "    'switch_box_flat', 'switch_box_public'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc97a7f-78e2-49dc-b205-4e7b620eb542",
   "metadata": {},
   "source": [
    "Необходимо добавить ещё 3 удаленных класса: place_toilets, place_bath, place_sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e02a6e5-4378-435a-b8ed-1c66b99f3156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(old_list_labels) + 3\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3886284-8f82-4cb0-a32a-313d2ed3b4c6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (stem): Sequential(\n",
       "    (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): ConvNeXtStage(\n",
       "      (downsample): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (6): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (7): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (8): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (9): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (10): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (11): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (12): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (13): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (14): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (15): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (16): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (17): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (18): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (19): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (20): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (21): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (22): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (23): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (24): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (25): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (26): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConvNeXtStage(\n",
       "      (downsample): Sequential(\n",
       "        (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): ConvNeXtBlock(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "          (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm_pre): Identity()\n",
       "  (head): Sequential(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=1536, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "\n",
    "model = timm.create_model('convnext_large_in22k', pretrained=False, num_classes=n_classes)\n",
    "checkpoint = torch.load(path_weights)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157eb44-2a38-44b7-94af-22e6567ea41a",
   "metadata": {},
   "source": [
    "В списке лейблов возьмем только те классы, которые есть в старой и новой модели. В старой модели необходимо исключить три удаленных из новой модели класса: place_toilets, place_bath, place_sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b23b658f-c6ea-4705-bdbb-72e6858ca2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[ACorrupt JPEG data: premature end of data segment\n",
      "  0%|          | 0/12 [00:11<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(dl_test):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f316133-301e-4f33-8e2b-7fdd9a51ecab",
   "metadata": {},
   "source": [
    "Отредактируем ground true, чтобы оставить только те лейблы, которые есть в обоих моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a8e8c4d-16f9-450d-b78f-50d2abfa3634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 33])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['targets'][:, :33].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9630337-f038-4084-a3f4-1d9145746d30",
   "metadata": {},
   "source": [
    "Отредактируем предсказания модели так, чтобы оставить только те лейблы, которые есть в обоих моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9466dccf-ab6b-47e7-9bda-54ce164c008a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    data, targets = data['image'].to(device), data['targets'].to(device)\n",
    "    \n",
    "    outputs = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fed7e94-f679-4180-bd60-cb8e6841a424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 33])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# индексы удаленных лейблов place_toilets, place_bath, place_sink\n",
    "exclude_indices = [24, 25, 26]\n",
    "\n",
    "mask = torch.ones(outputs.size(1), dtype=torch.bool).to(device)\n",
    "mask[exclude_indices] = 0\n",
    "\n",
    "new_outputs = torch.index_select(outputs, 1, torch.nonzero(mask).view(-1))\n",
    "\n",
    "new_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613eb3a9-f4c3-4e04-b90f-606a45c1e743",
   "metadata": {},
   "source": [
    "В выходе модели после корректировки у нас будут только лейблы, которые есть в обоих моделях, в обоих моделях не будет удаленных классов: place_toilets, place_bath, place_sink. Поэтому нужно уменьшить количество классов с которыми работает старая модель на 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5022a06-1300-44f9-aa0a-dd6f907a31dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes -= 3\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb554bc8-2b6b-401f-88e2-6037986328ff",
   "metadata": {},
   "source": [
    "Введем изменения в инфереренс модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca09bf2-8d7d-43a2-a61a-61628d60e4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]Corrupt JPEG data: premature end of data segment\n",
      " 17%|█▋        | 2/12 [00:25<02:06, 12.69s/it]Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 3038 extraneous bytes before marker 0xd9\n",
      " 42%|████▏     | 5/12 [01:03<01:30, 12.90s/it]Corrupt JPEG data: premature end of data segment\n",
      " 92%|█████████▏| 11/12 [02:21<00:12, 12.86s/it]Corrupt JPEG data: premature end of data segment\n",
      "100%|██████████| 12/12 [02:26<00:00, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test micro f1: 0.830\n",
      "Total test macro f1: 0.816\n",
      "room: 0.86\n",
      "bathroom: 0.69\n",
      "inner_corridor: 0.76\n",
      "public_place: 0.84\n",
      "floor_finish: 0.87\n",
      "floor_init: 0.78\n",
      "ceiling_finish: 0.92\n",
      "wall_finish: 0.92\n",
      "wall_init: 0.71\n",
      "door_room: 0.49\n",
      "toilet_yes: 0.73\n",
      "bath_yes: 0.82\n",
      "esocket_yes: 0.86\n",
      "kitchen_furniture_yes: 0.87\n",
      "radiator: 0.76\n",
      "floor_without: 0.74\n",
      "ceiling_without: 0.88\n",
      "wall_without: 0.82\n",
      "window_trim: 0.92\n",
      "window: 0.94\n",
      "floor_pipes: 0.91\n",
      "garbage: 0.78\n",
      "place_door: 0.87\n",
      "place_radiator: 0.74\n",
      "ventilation_shaft: 0.56\n",
      "sink_yes: 0.86\n",
      "conditioner: 1.00\n",
      "smoke_detector: 0.83\n",
      "ventilation_grille: 0.89\n",
      "fire_detectors: 0.91\n",
      "dynamics: 0.73\n",
      "switch_box_flat: 0.89\n",
      "switch_box_public: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "exclude_indices = [24, 25, 26]\n",
    "num_labels_old_model = 36\n",
    "mask = torch.ones(num_labels_old_model, dtype=torch.bool).to(device)\n",
    "mask[exclude_indices] = 0\n",
    "\n",
    "all_preds = np.array([]).reshape(0, n_classes) \n",
    "all_targets = np.array([]).reshape(0, n_classes) \n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dl_test):\n",
    "        data, targets = data['image'].to(device), data['targets'].to(device)\n",
    "            \n",
    "        outputs = model(data)\n",
    "        \n",
    "        outputs = torch.index_select(outputs, 1, torch.nonzero(mask).view(-1))\n",
    "\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        preds = torch.where(outputs > threshold, 1, 0)\n",
    "        all_preds = np.vstack((all_preds, preds.detach().cpu()))\n",
    "        all_targets = np.vstack((all_targets, targets[:, :33].detach().cpu()))\n",
    "    \n",
    "cms = multilabel_confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "micro_f1 = get_f1(all_preds, all_targets)\n",
    "all_subf1 = get_subf1(all_preds, all_targets)\n",
    "macro_f1 = sum(all_subf1) / n_classes\n",
    "\n",
    "print(f'Total test micro f1: {micro_f1:.03f}')\n",
    "print(f'Total test macro f1: {macro_f1:.03f}')\n",
    "\n",
    "for label, f1 in zip(old_list_labels, all_subf1):\n",
    "    print(f'{label}: {f1:.02f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b971537",
   "metadata": {},
   "source": [
    "### Confluence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e34ca7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def plot_cinfluence_for_one_label(label: str) -> None:\n",
    "    plt.figure(figsize = (8, 5))\n",
    "\n",
    "    label_id = {lab: i for i, lab in enumerate(list_labels)}\n",
    "\n",
    "    cm = cms[label_id[label]]\n",
    "\n",
    "    group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "    group_counts = cm.flatten()\n",
    "    group_percentages = [f'{v:.1%}' for v in cm.flatten()/np.sum(cm)]\n",
    "\n",
    "\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "      \n",
    "    sns.heatmap(cm,\n",
    "                annot=labels,\n",
    "                cmap='Blues',\n",
    "                fmt='',\n",
    "                annot_kws={\"fontsize\": 20})\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    micro_f1 = 2 * precision * recall / (recall + precision)\n",
    "\n",
    "    plt.title(f'Label: {label}', fontsize=18)\n",
    "    plt.xlabel(f'Predicted label \\n precision: {precision:.2} \\n recall: {recall:.2} \\n micro f1: {micro_f1:.2}', fontsize=18)\n",
    "    plt.ylabel('True label', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0ce487e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cinfluence_for_one_label(label = 'radiator')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s_iner_cv_clf_multi_decor_v0.1",
   "language": "python",
   "name": "s_iner_cv_clf_multi_decor_v0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
